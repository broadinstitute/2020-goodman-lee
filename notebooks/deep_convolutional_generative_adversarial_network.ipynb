{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep convolutional generative adversarial network (DCGAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import IPython\n",
    "import matplotlib.pyplot\n",
    "import numpy\n",
    "import sklearn.model_selection\n",
    "import tensorflow\n",
    "import tensorflow_probability\n",
    "import tqdm.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "DIMENSIONS = 128\n",
    "EPOCHS = 2048\n",
    "EXAMPLES = 16\n",
    "INPUT_SHAPE = (28, 28, 1)\n",
    "SEED = tensorflow.random.normal([EXAMPLES, DIMENSIONS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    image = tensorflow.image.resize(image, (28, 28))\n",
    "    \n",
    "    return tensorflow.image.rgb_to_grayscale(image)\n",
    "\n",
    "def render_images(images):\n",
    "    matplotlib.pyplot.figure(figsize=(12, 12))\n",
    "\n",
    "    for index, image in enumerate(images[:25]):\n",
    "        axis = matplotlib.pyplot.subplot(5, 5, index + 1)\n",
    "\n",
    "        matplotlib.pyplot.imshow(image[:, :, 0])\n",
    "\n",
    "        matplotlib.pyplot.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time x_0 = numpy.load(\"../data/objects/0.npy\")\n",
    "\n",
    "training_0, test_0 = sklearn.model_selection.train_test_split(x_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training, 0 (Membrane)\n",
    "\n",
    "training_0 = tensorflow.data.Dataset.from_tensor_slices(training_0)\n",
    "\n",
    "training_0 = training_0.map(preprocess, tensorflow.data.experimental.AUTOTUNE)\n",
    "\n",
    "training_0 = training_0.cache().shuffle(1024).batch(256).prefetch(tensorflow.data.experimental.AUTOTUNE)\n",
    "\n",
    "matplotlib.pyplot.figure(figsize=(12, 12))\n",
    "\n",
    "render_images([image.numpy() for image in training_0.take(1)][0][:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test, 0 (Membrane)\n",
    "\n",
    "test_0 = tensorflow.data.Dataset.from_tensor_slices(test_0)\n",
    "\n",
    "test_0 = test_0.map(preprocess, tensorflow.data.experimental.AUTOTUNE)\n",
    "\n",
    "test_0 = test_0.cache().shuffle(1024).batch(256).prefetch(tensorflow.data.experimental.AUTOTUNE)\n",
    "\n",
    "render_images([image.numpy() for image in test_0.take(1)][0][:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time x_1 = numpy.load(\"../data/objects/1.npy\")\n",
    "\n",
    "%time training_1, test_1 = sklearn.model_selection.train_test_split(x_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training, 1 (Foci)\n",
    "\n",
    "training_1 = tensorflow.data.Dataset.from_tensor_slices(training_1)\n",
    "\n",
    "training_1 = training_1.map(preprocess, tensorflow.data.experimental.AUTOTUNE)\n",
    "\n",
    "training_1 = training_1.cache().shuffle(1024).batch(256).prefetch(tensorflow.data.experimental.AUTOTUNE)\n",
    "\n",
    "matplotlib.pyplot.figure(figsize=(12, 12))\n",
    "\n",
    "render_images([image.numpy() for image in training_1.take(1)][0][:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test, 1 (Foci)\n",
    "\n",
    "test_1 = tensorflow.data.Dataset.from_tensor_slices(test_1)\n",
    "\n",
    "test_1 = test_1.map(preprocess, tensorflow.data.experimental.AUTOTUNE)\n",
    "\n",
    "test_1 = test_1.cache().shuffle(1024).batch(256).prefetch(tensorflow.data.experimental.AUTOTUNE)\n",
    "\n",
    "render_images([image.numpy() for image in test_1.take(1)][0][:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = tensorflow.keras.Sequential([\n",
    "    tensorflow.keras.layers.Dense(7 * 7 * 256, use_bias=False, input_shape=(DIMENSIONS,)),\n",
    "    tensorflow.keras.layers.BatchNormalization(),\n",
    "    tensorflow.keras.layers.LeakyReLU(),\n",
    "    tensorflow.keras.layers.Reshape((7, 7, 256)),\n",
    "    tensorflow.keras.layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False),\n",
    "    tensorflow.keras.layers.BatchNormalization(),\n",
    "    tensorflow.keras.layers.LeakyReLU(),\n",
    "    tensorflow.keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
    "    tensorflow.keras.layers.BatchNormalization(),\n",
    "    tensorflow.keras.layers.LeakyReLU(),\n",
    "    tensorflow.keras.layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'),\n",
    "])\n",
    "\n",
    "discriminator = tensorflow.keras.Sequential([\n",
    "    tensorflow.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=INPUT_SHAPE),\n",
    "    tensorflow.keras.layers.LeakyReLU(),\n",
    "    tensorflow.keras.layers.Dropout(0.3),\n",
    "    tensorflow.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'),\n",
    "    tensorflow.keras.layers.LeakyReLU(),\n",
    "    tensorflow.keras.layers.Dropout(0.3),\n",
    "    tensorflow.keras.layers.Flatten(),\n",
    "    tensorflow.keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tensorflow.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def generator_loss(y_pred):\n",
    "    return cross_entropy(tensorflow.ones_like(y_pred), y_pred)\n",
    "\n",
    "def discriminator_loss(y_true, y_pred):\n",
    "    return cross_entropy(tensorflow.ones_like(y_true), y_true) + cross_entropy(tensorflow.zeros_like(y_pred), y_pred)\n",
    "\n",
    "generator_optimizer = tensorflow.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "discriminator_optimizer = tensorflow.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_directory = \"./checkpoints\"\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_directory, \"ckpt\")\n",
    "\n",
    "checkpoint = tensorflow.train.Checkpoint(\n",
    "    discriminator_optimizer=discriminator_optimizer,\n",
    "    discriminator=discriminator,\n",
    "    generator_optimizer=generator_optimizer,\n",
    "    generator=generator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = generator(tensorflow.random.normal([1, 100]), training=False)\n",
    "\n",
    "discriminated = discriminator(generated)\n",
    "\n",
    "matplotlib.pyplot.imshow(generated[0, :, :, 0], cmap='gray')\n",
    "\n",
    "print(f\"discriminated: {discriminated[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = matplotlib.pyplot.figure(figsize=(12, 12))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        matplotlib.pyplot.subplot(4, 4, i + 1)\n",
    "        matplotlib.pyplot.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        matplotlib.pyplot.axis('off')\n",
    "\n",
    "    matplotlib.pyplot.savefig('./gif/image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    matplotlib.pyplot.show()\n",
    "\n",
    "@tensorflow.function\n",
    "def step(images):\n",
    "    noise = tensorflow.random.normal([BATCH_SIZE, DIMENSIONS])\n",
    "\n",
    "    with tensorflow.GradientTape() as generator_tape, tensorflow.GradientTape() as discriminator_tape:\n",
    "        generated = generator(noise, training=True)\n",
    "\n",
    "        y_true = discriminator(images, training=True)\n",
    "        y_pred = discriminator(generated, training=True)\n",
    "\n",
    "        loss_0 = generator_loss(y_pred)\n",
    "        loss_1 = discriminator_loss(y_true, y_pred)\n",
    "\n",
    "    generator_gradients = generator_tape.gradient(loss_0, generator.trainable_variables)\n",
    "    \n",
    "    discriminator_gradients = discriminator_tape.gradient(loss_1, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n",
    "    \n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))\n",
    "\n",
    "def fit(dataset, epochs=EPOCHS):\n",
    "    for epoch in range(epochs):\n",
    "        for image_batch in dataset:\n",
    "            step(image_batch)\n",
    "\n",
    "        IPython.display.clear_output(wait=True)\n",
    "\n",
    "        generate_and_save_images(generator, epoch + 1, SEED)\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "        IPython.display.clear_output(wait=True)\n",
    "\n",
    "        generate_and_save_images(generator, epochs, SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(training_1, 1024)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
